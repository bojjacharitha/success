\documentclass{beamer}
\mode<presentation>
\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{advdate}
\usepackage{adjustbox}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{multicol}
\usepackage{listings}
\usepackage{url}
\usepackage[dvips]{graphicx}
\usepackage{hyperref}
\hypersetup{colorlinks=true,linkcolor=winered,urlcolor=purple}
\def\UrlBreaks{\do\/\do-}
\usetheme{AnnArbor}
\usecolortheme{crane}
\setbeamertemplate{footline}
{
  \leavevmode%
  \hbox{%
  \begin{beamercolorbox}[wd=\paperwidth,ht=2.25ex,dp=1ex,right]{author in head/foot}%
    \insertframenumber{} / \inserttotalframenumber\hspace*{2ex}
  \end{beamercolorbox}}%
  \vskip0pt%
}
\setbeamertemplate{navigation symbols}{}

\providecommand{\nCr}[2]{\,^{#1}C_{#2}} % nCr
\providecommand{\nPr}[2]{\,^{#1}P_{#2}} % nPr
\providecommand{\mbf}{\mathbf}
\providecommand{\pr}[1]{\ensuremath{\Pr\left(#1\right)}}
\providecommand{\qfunc}[1]{\ensuremath{Q\left(#1\right)}}
\providecommand{\sbrak}[1]{\ensuremath{{}\left[#1\right]}}
\providecommand{\lsbrak}[1]{\ensuremath{{}\left[#1\right.}}
\providecommand{\rsbrak}[1]{\ensuremath{{}\left.#1\right]}}
\providecommand{\brak}[1]{\ensuremath{\left(#1\right)}}
\providecommand{\lbrak}[1]{\ensuremath{\left(#1\right.}}
\providecommand{\rbrak}[1]{\ensuremath{\left.#1\right)}}
\providecommand{\cbrak}[1]{\ensuremath{\left\{#1\right\}}}
\providecommand{\lcbrak}[1]{\ensuremath{\left\{#1\right.}}
\providecommand{\rcbrak}[1]{\ensuremath{\left.#1\right\}}}
\theoremstyle{remark}
\newtheorem{rem}{Remark}
\newcommand{\sgn}{\mathop{\mathrm{sgn}}}
\providecommand{\abs}[1]{\left\vert#1\right\vert}
\providecommand{\res}[1]{\Res\displaylimits_{#1}}
\providecommand{\norm}[1]{\lVert#1\rVert}
\providecommand{\mtx}[1]{\mathbf{#1}}
\providecommand{\mean}[1]{E\left[ #1 \right]}
\providecommand{\fourier}{\overset{\mathcal{F}}{ \rightleftharpoons}}
%\providecommand{\hilbert}{\overset{\mathcal{H}}{ \rightleftharpoons}}
\providecommand{\system}{\overset{\mathcal{H}}{ \longleftrightarrow}}
%\newcommand{\solution}[2]{\textbf{Solution:}{#1}}
%\newcommand{\solution}{\noindent \textbf{Solution: }}
\providecommand{\dec}[2]{\ensuremath{\overset{#1}{\underset{#2}{\gtrless}}}}
\newcommand{\myvec}[1]{\ensuremath{\begin{pmatrix}#1\end{pmatrix}}}
\let\vec\mathbf

\lstset{
%language=C,
frame=single,
breaklines=true,
columns=fullflexible
}

\numberwithin{equation}{section}

\title{Intro to AI and ML\\Voice controlled bot}
\author{B Charitha Reddy\\ EE19BTECH11001\\ Electrical Engineering\\IIT Hyderabad.}

\date{\today}
\begin{document}

\begin{frame}
\titlepage
\end{frame}

\section*{Outline}
\begin{frame}
\tableofcontents
\end{frame}


\begin{frame}
\section{More Samples generation}
\frametitle{More Samples generation}
Create an empty array to generate new file from original file.

We have to then read the audio files recorded already using soundfile.

Use a for loop for generating more samples.

Add empty elements in the start and in the end to the array.Let the initial data elements be in the middle of the array.

So,an array of total length 25000 is created and audio files are written back to the hard disk.

Finally more voice files are created using the initial 80 voice files for each command.
\end{frame}
\begin{frame}
\section{Math in the code}
\frametitle{Math in the code}
Create data and label named empty arrays.

Then compute the mfcc as a feature vector of dimension (49,39).

As there cannot be 49 time steps,fill the rest of the array (39,49-x) with 0's.

Then use np.append to add the two arrays with dimensions (39,x) and (39,49-x).

Now transpose it to get mfcc feature vector of (49,39) dimension.


\url{https://github.com/bojjacharitha/success/blob/master/25files.py}
\end{frame}
\begin{frame}
\frametitle{Math in the code}
After performing the MFCC on the input sound files we get an output matrix of 49x39 i.e. 49 time steps with each having 39 features.

The data is a 3-D array with (9480,49,39) .

label array is an array with the elments \{0,1,2,3,4\} as one row,similarly others are created.


\includegraphics[scale=0.6]{../Desktop/gvvtoycar1.png} 
\end{frame}
\begin{frame}
\section{softmax function}
\frametitle{softmax function}
\includegraphics[scale=0.5]{../gvvtoycar.png} 



It squashes a vector in the range (0, 1) and all the resulting elements add up to 1.



$f(\hat{y_i})=\frac{e^{\hat{y_i}}}{\sum_{j}{C}e^{\hat{y_j}}}$
\end{frame}
\begin{frame}
\section{Categorical loss function}
\frametitle{Categorical loss function}
keras.utils.to\_categorical converts\: a \:class\: vector\: (integers)\: to\: binary\: class\: matrix. 

It is the implementation of categorical loss function from scratch.

The input to the function is predicted probability and a one hot vector.

It computes the loss .
Categorical Cross entropy:
$$E = -\sum_{i=0}^{C} {y_i}{log{\hat{y_i}}} $$
where C is the total number of classes.
\end{frame}

\begin{frame}
\section{LSTM}
\frametitle{LSTM}
The model contains a lstm layer to exploit the sequential nature of sound files.

 
It is followed by maxpooling for eliminating the unnecesary information.

Then it is flattened and sent to the dense layer with 5 nodes with softmax as activation.

It is the layer for probability prediction.
\end{frame}


%\begin{frame}
%\frametitle{Introduction}
%\framesubtitle{Literature} 
%%\begin{figure}[t!]
%%    \centering
%%    \begin{subfigure}[t]{0.4\columnwidth}
%%        \centering
%%        \includegraphics[width=\columnwidth]{point_source}
%%        \caption{Single point source}
%%\label{fig3:subfig1}        
%%    \end{subfigure}%
%%    ~
%%    \begin{subfigure}[t]{0.4\columnwidth}
%%        \centering
%%        \includegraphics[width=\columnwidth]{pointNoPowerDist_new}
%%        \caption{SNR profile}
%%\label{fig3:subfig2}
%%    \end{subfigure}
%%  %  \caption{Average SNR for a BPP. $N=16$}
%%    \label{fig3}
%%  \end{figure}
%
%\end{frame}
%  
%
%
%%

\end{document}